{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs2278-cornell/ORIE_4580_Final_Project/blob/main/Simulation_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block 1 – Service-time model setup and sanity check\n",
        "\n",
        "This block initializes the core batch service-time model that underlies the GPU simulator and verifies that it behaves as expected before introducing arrivals and scheduling.\n",
        "\n",
        "---\n",
        "\n",
        "#### Model parameters\n",
        "\n",
        "The following constants implement the piecewise-linear latency model from the project description (Llama-3-70B example):\n",
        "\n",
        "- `C_SETUP = 45.5` ms – fixed setup cost per batch.\n",
        "- `A_MARGINAL = 0.30` ms/token – marginal cost per token beyond a threshold.\n",
        "- `B0_THRESHOLD = 64` tokens – batch-size threshold `b0`.\n",
        "\n",
        "The intended batch service time for a batch with token load `b` is\n",
        "\n",
        "`S(b) = c + a * max(0, b - b0)`\n",
        "\n",
        "where `c = C_SETUP`, `a = A_MARGINAL`, and `b0 = B0_THRESHOLD`.  \n",
        "The implementation returns `S(b)` in seconds.\n",
        "\n",
        "---\n",
        "\n",
        "#### Data structures\n",
        "\n",
        "- **Request**  \n",
        "  Simple dataclass representing a single LLM query, with:\n",
        "  - `arrival_time` – arrival timestamp (seconds),\n",
        "  - `prompt_len` – input length in tokens,\n",
        "  - `output_budget` – planned decode length in tokens,\n",
        "  - tracking fields `start_time`, `finish_time`, and `tokens_generated`.\n",
        "\n",
        "  In this block, `Request` is mainly illustrative; richer state (for TTFT and decode tokens) is introduced in later blocks.\n",
        "\n",
        "- **GPUServer**  \n",
        "  Minimal GPU worker abstraction that:\n",
        "  - Stores `max_batch_size`,\n",
        "  - Maintains `queue` and `active_batch` lists (placeholders for later scheduling logic),\n",
        "  - Implements the batch service-time function:\n",
        "\n",
        "    ```python\n",
        "    ms_time = C_SETUP + A_MARGINAL * max(0, batch_token_load - B0_THRESHOLD)\n",
        "    return ms_time / 1000.0\n",
        "    ```\n",
        "\n",
        "---\n",
        "\n",
        "#### Sanity check of the service-time model\n",
        "\n",
        "At the end of the block, a small diagnostic is performed:\n",
        "\n",
        "- Instantiate `GPUServer(max_batch_size=8)`.\n",
        "- Evaluate `calc_service_time` for several batch token loads:\n",
        "\n",
        "  ```python\n",
        "  test_loads = [10, 64, 100, 500]\n"
      ],
      "metadata": {
        "id": "NV5ogFwwSsuZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0GgOpspCMTk",
        "outputId": "7ed60792-ec40-4b47-c688-9d0f9705971f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Service Model Validation ---\n",
            "Parameters: c=45.5ms, a=0.3ms/tok, b0=64\n",
            "Token Load:  10 -> Service Time: 0.0455 sec\n",
            "Token Load:  50 -> Service Time: 0.0455 sec\n",
            "Token Load: 100 -> Service Time: 0.0563 sec\n",
            "Token Load: 500 -> Service Time: 0.1763 sec\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Optional\n",
        "\n",
        "# Setup cost (ms), Marginal cost (ms/token), Batch threshold\n",
        "C_SETUP = 45.5\n",
        "A_MARGINAL = 0.30\n",
        "B0_THRESHOLD = 64\n",
        "\n",
        "@dataclass\n",
        "class Request:\n",
        "    \"\"\"\n",
        "    Represents a single LLM query (User Job).\n",
        "    Tracks its lifecycle statistics for output analysis.\n",
        "    \"\"\"\n",
        "    req_id: int\n",
        "    arrival_time: float\n",
        "    prompt_len: int      # Tokens in input\n",
        "    output_budget: int   # Tokens to generate\n",
        "\n",
        "    # Tracking Metrics\n",
        "    start_time: float = -1.0\n",
        "    finish_time: float = -1.0\n",
        "    tokens_generated: int = 0\n",
        "\n",
        "    def remaining_tokens(self) -> int:\n",
        "        return self.output_budget - self.tokens_generated\n",
        "\n",
        "class GPUServer:\n",
        "    \"\"\"\n",
        "    Represents the GPU Worker.\n",
        "    Manages the queue and calculates service times based on the\n",
        "    piecewise linear model S(b) = c + a * max(0, b - b0).\n",
        "    \"\"\"\n",
        "    def __init__(self, max_batch_size: int):\n",
        "        self.max_batch_size = max_batch_size\n",
        "        self.queue: List[Request] = [] # The waiting line\n",
        "        self.active_batch: List[Request] = [] # Jobs currently on GPU\n",
        "        self.is_busy: bool = False\n",
        "\n",
        "    def calc_service_time(self, batch_token_load: int) -> float:\n",
        "        \"\"\"\n",
        "        Calculates processing time in SECONDS.\n",
        "        Formula: c + a * max(0, b - b0) (from project specs)\n",
        "        \"\"\"\n",
        "        ms_time = C_SETUP + A_MARGINAL * max(0, batch_token_load - B0_THRESHOLD)\n",
        "        return ms_time / 1000.0  # Convert ms to seconds\n",
        "\n",
        "    def add_to_queue(self, req: Request):\n",
        "        self.queue.append(req)\n",
        "\n",
        "# --- Validation of \"Physics\" ---\n",
        "# Let's test if the service time calculation matches the linear model expectation.\n",
        "# This serves as a sanity check before building the complex loop.\n",
        "\n",
        "server = GPUServer(max_batch_size=8)\n",
        "test_loads = [10, 50, 100, 500]\n",
        "\n",
        "print(\"--- Service Model Validation ---\")\n",
        "print(f\"Parameters: c={C_SETUP}ms, a={A_MARGINAL}ms/tok, b0={B0_THRESHOLD}\")\n",
        "for load in test_loads:\n",
        "    duration = server.calc_service_time(load)\n",
        "    print(f\"Token Load: {load:3d} -> Service Time: {duration:.4f} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block 2 – Simulation engine and baseline scheduling policy\n",
        "\n",
        "This block implements the core **discrete-event simulation** of a single-GPU LLM server.  \n",
        "It adds an arrival process, a simple scheduling policy, and per-request latency metrics on top of the batch service-time model from Block 1.\n",
        "\n",
        "---\n",
        "\n",
        "#### Configuration and state\n",
        "\n",
        "- Global parameters (units as in the handout):\n",
        "  - `DEFAULT_C`, `DEFAULT_A`, `DEFAULT_B0` – default values for `c`, `a`, and `b0`.\n",
        "  - `CURRENT_C`, `CURRENT_B0` – mutable versions used in `calc_service_time`.  \n",
        "    These are overridden in the validation block to emulate an M/M/1 system.\n",
        "\n",
        "- `Request` dataclass:\n",
        "  - Fields:\n",
        "    - `req_id` – integer request identifier,\n",
        "    - `arrival_time` – arrival timestamp (seconds),\n",
        "    - `prompt_len` – prompt length `L_i` (tokens),\n",
        "    - `output_budget` – output budget `B_i` (tokens),\n",
        "    - `start_time` – time when the request first enters a GPU batch,\n",
        "    - `finish_time` – completion time,\n",
        "    - `tokens_decoded` – number of decode tokens produced so far.\n",
        "  - Property:\n",
        "    - `is_complete` – `True` once `tokens_decoded >= output_budget`.\n",
        "\n",
        "- `GPUServer`:\n",
        "  - Stores `max_batch_size` (number of jobs per batch).\n",
        "  - Maintains:\n",
        "    - `queue` – FCFS waiting line,\n",
        "    - `active_batch` – set of requests currently on the GPU.\n",
        "  - Method:\n",
        "    - `calc_service_time(batch_token_load)` – computes service time in seconds via  \n",
        "      `ms_time = CURRENT_C + DEFAULT_A * max(0, batch_token_load - CURRENT_B0)`  \n",
        "      followed by division by 1000.\n",
        "\n",
        "---\n",
        "\n",
        "#### Arrival process and job sizes\n",
        "\n",
        "Function: `run_simulation(arrival_rate_lambda, max_duration, batch_size, fixed_prompt_len=None, fixed_output_len=None)`\n",
        "\n",
        "- Arrival process:\n",
        "  - Uses a Poisson process with rate `lambda` (`arrival_rate_lambda`).\n",
        "  - Interarrival times are drawn as `Exp(lambda)` using `random.expovariate`.\n",
        "  - Requests are generated until `t >= max_duration`.\n",
        "\n",
        "- Job size generation:\n",
        "  - If `fixed_prompt_len` / `fixed_output_len` are provided, all jobs are identical in size  \n",
        "    (used in the validation block).\n",
        "  - Otherwise:\n",
        "    - `prompt_len` is drawn uniformly from `[50, 200]` tokens,\n",
        "    - `output_budget` is fixed at 20 tokens (baseline choice for the demo).\n",
        "\n",
        "All generated requests are stored in `all_requests`, sorted implicitly by arrival time.\n",
        "\n",
        "---\n",
        "\n",
        "#### Event loop and scheduling logic\n",
        "\n",
        "The main loop runs while either:\n",
        "- the simulation time `current_time` is less than `max_duration`, or\n",
        "- there are still jobs in `active_batch`.\n",
        "\n",
        "Within the loop:\n",
        "\n",
        "1. **Admission**  \n",
        "   - All jobs with `arrival_time <= current_time` are moved from `all_requests` into `server.queue`.\n",
        "   - This implements an FCFS waiting line.\n",
        "\n",
        "2. **Idle jump**  \n",
        "   - If both `active_batch` and `queue` are empty but more arrivals exist,  \n",
        "     `current_time` is advanced to the next arrival time.  \n",
        "   - If there are no active jobs and no future arrivals, the simulation terminates.\n",
        "\n",
        "3. **Batch formation (FCFS)**  \n",
        "   - While `queue` is non-empty and `active_batch` has capacity `< max_batch_size`,  \n",
        "     the earliest request is popped from `queue`, `start_time` is set to `current_time`,  \n",
        "     and the request is appended to `active_batch`.\n",
        "\n",
        "4. **Service step: prefill vs decode**\n",
        "\n",
        "   - `needs_prefill = any(r.tokens_decoded == 0 for r in batch)`.\n",
        "\n",
        "   - **Prefill phase** (at least one request not yet prefills):\n",
        "     - Batch token load `b` is computed as the sum of `prompt_len` over `batch`.\n",
        "     - Service time is `calc_service_time(b)`; `current_time` is advanced by this amount.\n",
        "     - All requests with `tokens_decoded == 0` are marked as having produced their first token by setting `tokens_decoded = 1`.  \n",
        "       (This models the first decode token becoming available immediately after prefill.)\n",
        "\n",
        "   - **Decode phase** (all requests already prefills):\n",
        "     - Batch token load is `len(batch)` (one token per active request).\n",
        "     - Service time is `calc_service_time(len(batch))`; `current_time` is advanced.\n",
        "     - Each request in `batch` increments `tokens_decoded` by 1.\n",
        "     - Requests for which `is_complete` becomes `True` record `finish_time = current_time` and are removed from `active_batch`.\n",
        "\n",
        "This yields a **batched prefill + round-robin decode** scheduling policy:\n",
        "- Prefill is batched over all active queries.\n",
        "- Decode produces one token per request per decode step, shared across the batch.\n",
        "\n",
        "---\n",
        "\n",
        "#### Output metrics\n",
        "\n",
        "After the event loop finishes, the function assembles a `pandas.DataFrame` with one row per completed request:\n",
        "\n",
        "- `Request ID` – identifier,\n",
        "- `Arrival` – arrival time,\n",
        "- `Finish` – completion time,\n",
        "- `Latency` – total response time `Finish - Arrival`,\n",
        "- `TTFT` – approximated as `start_time - arrival_time` (queueing delay plus scheduling delay up to first GPU service).\n",
        "\n",
        "These fields feed into the visualization block (histograms and throughput plots) and provide the basic metrics required for the demo: latency distribution and an approximation of TTFT.\n"
      ],
      "metadata": {
        "id": "fJ3tj25lTxzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility for the demo\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# --- Constants from Project Description ---\n",
        "C_SETUP = 45.5        # ms (setup time per batch)\n",
        "A_MARGINAL = 0.30     # ms/token beyond threshold\n",
        "B0_THRESHOLD = 64     # tokens (batch-size threshold)\n",
        "\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Request:\n",
        "    \"\"\"\n",
        "    Represents a single LLM query (user job).\n",
        "    All times are in SECONDS.\n",
        "    \"\"\"\n",
        "    req_id: int\n",
        "    arrival_time: float\n",
        "    prompt_len: int      # L_i: tokens in the input prompt\n",
        "    output_budget: int   # B_i: max response length (tokens)\n",
        "\n",
        "    # State tracking\n",
        "    start_time: float = -1.0\n",
        "    finish_time: float = -1.0\n",
        "    tokens_decoded: int = 0\n",
        "    first_token_time: float = -1.0  # for TTFT\n",
        "\n",
        "    @property\n",
        "    def is_complete(self) -> bool:\n",
        "        return self.tokens_decoded >= self.output_budget\n",
        "\n",
        "class GPUServer:\n",
        "    \"\"\"\n",
        "    Single GPU worker with batched processing.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_batch_size: int):\n",
        "        self.max_batch_size = max_batch_size\n",
        "        self.queue: List[Request] = []\n",
        "        self.active_batch: List[Request] = []\n",
        "\n",
        "    def calc_service_time(self, batch_token_load: int) -> float:\n",
        "        \"\"\"\n",
        "        Calculates processing time in SECONDS using:\n",
        "            S(b) = c + a * max(0, b - b0)\n",
        "        where b is the batch token load.\n",
        "        \"\"\"\n",
        "        ms_time = C_SETUP + A_MARGINAL * max(0, batch_token_load - B0_THRESHOLD)\n",
        "        return ms_time / 1000.0  # convert ms -> seconds\n",
        "\n",
        "def run_simulation(arrival_rate_lambda: float = 1.0,\n",
        "                   max_duration: float = 60.0,\n",
        "                   max_batch_size: int = 4) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Runs a discrete-event simulation for a single-GPU batched LLM server.\n",
        "\n",
        "    Scheduling:\n",
        "      - FCFS admission into batches up to max_batch_size\n",
        "      - Prefill: batched over all jobs that have not been prefills yet\n",
        "      - Decode: round-robin, 1 token per job in the active batch per step\n",
        "\n",
        "    Returns:\n",
        "      DataFrame with per-request metrics including TTFT and avg TBT.\n",
        "    \"\"\"\n",
        "    server = GPUServer(max_batch_size=max_batch_size)\n",
        "    current_time = 0.0\n",
        "    completed_requests: List[Request] = []\n",
        "\n",
        "    # --- Generate arrivals (Poisson process) ---\n",
        "    all_requests: List[Request] = []\n",
        "    t = 0.0\n",
        "    req_id = 0\n",
        "\n",
        "    B_MAX = 32      # cap for output budget\n",
        "    p_geom = 0.15   # geometric parameter for B_i\n",
        "\n",
        "    while t < max_duration:\n",
        "        dt = random.expovariate(arrival_rate_lambda)\n",
        "        t += dt\n",
        "        if t >= max_duration:\n",
        "            break\n",
        "\n",
        "        # Prompt length L_i (simple uniform for now)\n",
        "        prompt_len = random.randint(50, 200)\n",
        "\n",
        "        # Output budget B_i ~ Geometric(p), capped at B_MAX\n",
        "        raw_length = np.random.geometric(p_geom)  # 1, 2, ...\n",
        "        output_budget = int(min(max(raw_length, 1), B_MAX))\n",
        "\n",
        "        r = Request(\n",
        "            req_id=req_id,\n",
        "            arrival_time=t,\n",
        "            prompt_len=prompt_len,\n",
        "            output_budget=output_budget\n",
        "        )\n",
        "        all_requests.append(r)\n",
        "        req_id += 1\n",
        "\n",
        "    print(f\"--- Simulation Started: {len(all_requests)} requests generated ---\")\n",
        "\n",
        "    arrival_index = 0\n",
        "\n",
        "    # --- Main simulation loop ---\n",
        "    while current_time < max_duration or server.active_batch:\n",
        "        # Admit arrivals whose arrival_time <= current_time\n",
        "        while arrival_index < len(all_requests):\n",
        "            next_req = all_requests[arrival_index]\n",
        "            if next_req.arrival_time <= current_time:\n",
        "                server.queue.append(next_req)\n",
        "                arrival_index += 1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        # If system idle and more arrivals in future, jump to next arrival\n",
        "        if not server.active_batch and not server.queue and arrival_index < len(all_requests):\n",
        "            current_time = all_requests[arrival_index].arrival_time\n",
        "            continue\n",
        "\n",
        "        # If system empty and no more arrivals, stop\n",
        "        if not server.active_batch and not server.queue and arrival_index >= len(all_requests):\n",
        "            break\n",
        "\n",
        "        # Fill active batch (FCFS) up to max_batch_size\n",
        "        while server.queue and len(server.active_batch) < server.max_batch_size:\n",
        "            req = server.queue.pop(0)\n",
        "            if req.start_time < 0:\n",
        "                req.start_time = current_time\n",
        "            server.active_batch.append(req)\n",
        "\n",
        "        batch = server.active_batch\n",
        "        if not batch:\n",
        "            continue\n",
        "\n",
        "        # Decide between PREFILL vs DECODE\n",
        "        needs_prefill = any(r.tokens_decoded == 0 for r in batch)\n",
        "\n",
        "        if needs_prefill:\n",
        "            # --- PREFILL PHASE ---\n",
        "            # Only count prompts for requests that still need prefill\n",
        "            batch_load = sum(r.prompt_len for r in batch if r.tokens_decoded == 0)\n",
        "            step_duration = server.calc_service_time(batch_load)\n",
        "            prefill_end_time = current_time + step_duration\n",
        "            current_time = prefill_end_time\n",
        "\n",
        "            for r in batch:\n",
        "                if r.tokens_decoded == 0:\n",
        "                    # First token becomes available right after prefill\n",
        "                    r.tokens_decoded = 1\n",
        "                    if r.first_token_time < 0:\n",
        "                        r.first_token_time = prefill_end_time\n",
        "        else:\n",
        "            # --- DECODE PHASE ---\n",
        "            # One token per request in the batch\n",
        "            batch_load = len(batch)\n",
        "            step_duration = server.calc_service_time(batch_load)\n",
        "            current_time += step_duration\n",
        "\n",
        "            finished_indices = []\n",
        "            for i, r in enumerate(batch):\n",
        "                r.tokens_decoded += 1\n",
        "                if r.is_complete:\n",
        "                    r.finish_time = current_time\n",
        "                    completed_requests.append(r)\n",
        "                    finished_indices.append(i)\n",
        "\n",
        "            # Remove completed jobs from the active batch\n",
        "            for i in sorted(finished_indices, reverse=True):\n",
        "                server.active_batch.pop(i)\n",
        "\n",
        "    # --- Compile per-request metrics ---\n",
        "    results = []\n",
        "    for r in completed_requests:\n",
        "        # Time To First Token (TTFT)\n",
        "        if r.first_token_time > 0:\n",
        "            ttft = r.first_token_time - r.arrival_time\n",
        "        else:\n",
        "            ttft = None\n",
        "\n",
        "        # Total completion latency (arrival -> last token)\n",
        "        completion_latency = r.finish_time - r.arrival_time\n",
        "\n",
        "        # Average Time Between Tokens (from first to last)\n",
        "        if r.first_token_time > 0 and r.output_budget > 1:\n",
        "            avg_tbt = (r.finish_time - r.first_token_time) / (r.output_budget - 1)\n",
        "        else:\n",
        "            avg_tbt = None\n",
        "\n",
        "        results.append({\n",
        "            \"request_id\": r.req_id,\n",
        "            \"arrival_time\": r.arrival_time,\n",
        "            \"first_token_time\": r.first_token_time,\n",
        "            \"completion_time\": r.finish_time,\n",
        "            \"completion_latency\": completion_latency,  # end-to-end latency\n",
        "            \"TTFT\": ttft,                               # Time To First Token\n",
        "            \"avg_TBT\": avg_tbt,                         # average Time Between Tokens\n",
        "            \"output_tokens\": r.output_budget\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Quick test run for the demo\n",
        "df_results = run_simulation(arrival_rate_lambda=2.0, max_duration=10.0, max_batch_size=4)\n",
        "print(\"\\n--- Simulation Complete ---\")\n",
        "print(df_results.head().to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB0-2XxEPa9y",
        "outputId": "58dde210-602f-4fb2-d3cb-03c327d83001"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Simulation Started: 12 requests generated ---\n",
            "\n",
            "--- Simulation Complete ---\n",
            " request_id  arrival_time  first_token_time  completion_time  completion_latency     TTFT  avg_TBT  output_tokens\n",
            "          0      0.930304          1.003704         1.266004            0.335700 0.073400 0.065575              5\n",
            "          1      0.950967          1.084004         1.466904            0.515937 0.133037 0.054700              8\n",
            "          2      1.283663          1.375904         1.603404            0.319741 0.092241 0.045500              6\n",
            "          3      3.001557          3.070157         3.252157            0.250600 0.068600 0.045500              5\n",
            "          4      3.439350          3.497150         3.633650            0.194300 0.057800 0.045500              4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block 3 – Visualization: latency distribution and throughput\n",
        "\n",
        "This block generates basic visual metrics from the simulation output.  \n",
        "It operates on the `pandas.DataFrame` returned by `run_simulation`, which contains per-request fields:\n",
        "\n",
        "- `TTFT` – time from arrival until first service (Time To First Token approximation),\n",
        "- `Latency` – total response time (completion time minus arrival time),\n",
        "- `Finish` – completion time of each request.\n",
        "\n",
        "---\n",
        "\n",
        "#### Latency distribution\n",
        "\n",
        "The first subplot produces overlaid histograms of:\n",
        "\n",
        "- `TTFT`\n",
        "- `Latency` (total completion latency)\n",
        "\n",
        "using 15 bins each. This plot summarizes the distribution of user-visible delays:\n",
        "\n",
        "- how quickly the first token is seen (TTFT),\n",
        "- how long it takes to receive the full response (total latency).\n",
        "\n",
        "The plot title and legend explicitly distinguish between these two latency notions.\n",
        "\n",
        "---\n",
        "\n",
        "#### Throughput over time\n",
        "\n",
        "The second subplot estimates **throughput** as requests completed per second:\n",
        "\n",
        "- The time axis is partitioned into 5-second windows from 0 up to `max_t = df[\"Finish\"].max()`.\n",
        "- For each window, the number of completions is counted via `np.histogram(df[\"Finish\"], bins=bins)`.\n",
        "- Counts are divided by the window length (5 seconds) to obtain an average **requests per second** rate for each interval.\n",
        "- The result is plotted as a line (`counts / 5.0` versus the left edge of each time bin).\n",
        "\n",
        "This shows how the system’s completion rate evolves over the course of the simulation (e.g., warm-up vs. steady state behavior).\n"
      ],
      "metadata": {
        "id": "4Fk49VaQVNa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- VISUALIZATION BLOCK ---\n",
        "def plot_results(df):\n",
        "    \"\"\"\n",
        "    Generates the plots for the demo:\n",
        "    1. Latency histogram (TTFT and total completion latency)\n",
        "    2. Throughput over time (requests completed per second)\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data to plot.\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Plot 1: Latency Distribution (TTFT vs Total Latency)\n",
        "    ttft_vals = df[\"TTFT\"].dropna()\n",
        "    total_lat = df[\"completion_latency\"].dropna()\n",
        "\n",
        "    axes[0].hist(ttft_vals, bins=20, alpha=0.7, label=\"Time To First Token (TTFT)\")\n",
        "    axes[0].hist(total_lat, bins=20, alpha=0.5, label=\"Total Completion Latency\")\n",
        "    axes[0].set_xlabel(\"Time (seconds)\")\n",
        "    axes[0].set_ylabel(\"Count\")\n",
        "    axes[0].set_title(\"Distribution of Latencies\")\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: Throughput (requests completed per 2-second window)\n",
        "    max_time = df[\"completion_time\"].max()\n",
        "    time_bins = np.arange(0, max_time + 2, 2)  # 2-second windows\n",
        "    throughput_counts, _ = np.histogram(df[\"completion_time\"], bins=time_bins)\n",
        "\n",
        "    # Convert counts to Requests Per Second (divide by window size = 2s)\n",
        "    throughput_rps = throughput_counts / 2.0\n",
        "\n",
        "    axes[1].plot(time_bins[:-1], throughput_rps, marker=\"o\", linestyle=\"-\")\n",
        "    axes[1].set_xlabel(\"Simulation Time (s)\")\n",
        "    axes[1].set_ylabel(\"Throughput (req/s)\")\n",
        "    axes[1].set_title(\"System Throughput Over Time\")\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print Summary Stats\n",
        "    print(\"\\n--- Summary Metrics ---\")\n",
        "    print(f\"Mean TTFT:           {ttft_vals.mean():.4f} s\")\n",
        "    print(f\"Mean total latency:  {total_lat.mean():.4f} s\")\n",
        "    print(f\"P95 total latency:   {total_lat.quantile(0.95):.4f} s\")\n",
        "    print(f\"Total throughput:    {len(df) / max_time:.2f} req/s\")\n",
        "\n",
        "    # Optional: TBT summary if you want to mention it\n",
        "    if \"avg_TBT\" in df.columns:\n",
        "        avg_tbt_vals = df[\"avg_TBT\"].dropna()\n",
        "        if not avg_tbt_vals.empty:\n",
        "            print(f\"Mean avg_TBT:        {avg_tbt_vals.mean():.4f} s\")\n",
        "\n",
        "# Run the visualizer on your previous results\n",
        "plot_results(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "CUI1xRZ-P8-Z",
        "outputId": "f4d50a6a-f20a-4524-b00a-0b03aeda1add"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Summary Metrics ---\n",
            "Mean TTFT:           0.0732 s\n",
            "Mean total latency:  0.3926 s\n",
            "P95 total latency:   0.8050 s\n",
            "Total throughput:    1.18 req/s\n",
            "Mean avg_TBT:        0.0486 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block 4 – Validation against M/M/1 queueing theory\n",
        "\n",
        "This block provides a **model validation step** by specializing the simulator to a simple setting where classical queueing theory applies, and comparing simulated latencies to the M/M/1 closed-form expression.\n",
        "\n",
        "---\n",
        "\n",
        "#### Goal\n",
        "\n",
        "Show that, in a simplified configuration with:\n",
        "\n",
        "- a single server (single GPU),\n",
        "- no batching,\n",
        "- no setup cost,\n",
        "- constant job sizes (hence constant service time),\n",
        "\n",
        "the simulator produces a mean response time that is consistent with the **M/M/1** result:\n",
        "\n",
        "`E[T] = 1 / (μ - λ)`\n",
        "\n",
        "where `λ` is the arrival rate and `μ` is the service rate.\n",
        "\n",
        "This corresponds to the “compare to M/M/1” validation idea in the project description.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 1 – Override service-time “physics”\n",
        "\n",
        "Function: `run_mm1_validation()`\n",
        "\n",
        "Inside this function, the batch service model is simplified:\n",
        "\n",
        "- `CURRENT_C = 0.0` – removes the per-batch setup cost `c`.\n",
        "- `CURRENT_B0 = 0` – removes the batch-size threshold `b0`.\n",
        "\n",
        "With these settings, the service time in `calc_service_time` becomes\n",
        "\n",
        "`S(b) = A_MARGINAL * b`\n",
        "\n",
        "and, with `batch_size = 1`, each request is processed as a single “batch” with a fixed token count.\n",
        "\n",
        "---\n",
        "\n",
        "#### Step 2 – Fix job size and compute μ\n",
        "\n",
        "Parameters:\n",
        "\n",
        "- Arrival rate `λ = lam = 5.0` (queries per second).\n",
        "- Job structure:\n",
        "  - `prompt_len = 100` tokens,\n",
        "  - `decode_len = 1` token,\n",
        "  - `total_tokens = 101`.\n",
        "\n",
        "The average service time per job (in seconds) is:\n",
        "\n",
        "```python\n",
        "avg_service_time = (DEFAULT_A * total_tokens) / 1000.0\n",
        "mu = 1.0 / avg_service_time\n"
      ],
      "metadata": {
        "id": "E0eQsMkpVgxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- define this missing variable ---\n",
        "A_MARGINAL = 0.30  # ms per token\n",
        "\n",
        "# --- 3. VISUALIZATION (TTFT, Latency, Cumulative Throughput) ---\n",
        "def plot_demo_metrics(df):\n",
        "    if df.empty:\n",
        "        print(\"No data to plot.\")\n",
        "        return\n",
        "\n",
        "    ttft_vals = df[\"TTFT\"].dropna()\n",
        "    lat_col = \"Latency\" if \"Latency\" in df.columns else \"completion_latency\"\n",
        "    finish_col = \"Finish\" if \"Finish\" in df.columns else \"completion_time\"\n",
        "\n",
        "    lat_vals = df[lat_col].dropna()\n",
        "    max_t = df[finish_col].max()\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
        "\n",
        "    axes[0].hist(ttft_vals, bins=20, alpha=0.8)\n",
        "    axes[0].set_title(\"TTFT distribution\")\n",
        "    axes[0].set_xlabel(\"TTFT (seconds)\")\n",
        "    axes[0].set_ylabel(\"Count\")\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1].hist(lat_vals, bins=20, alpha=0.8)\n",
        "    axes[1].set_title(\"Total latency distribution\")\n",
        "    axes[1].set_xlabel(\"Latency (seconds)\")\n",
        "    axes[1].set_ylabel(\"Count\")\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    completion_times = np.sort(df[finish_col].values)\n",
        "    time_grid = np.arange(1, int(np.ceil(max_t)) + 1)\n",
        "    completed_counts = np.searchsorted(completion_times, time_grid, side=\"right\")\n",
        "    avg_throughput = completed_counts / time_grid\n",
        "\n",
        "    axes[2].plot(time_grid, avg_throughput, marker=\"o\")\n",
        "    axes[2].set_title(\"Cumulative average throughput\")\n",
        "    axes[2].set_xlabel(\"Time t (s)\")\n",
        "    axes[2].set_ylabel(\"Avg throughput 0–t (req/s)\")\n",
        "    axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n--- Summary metrics ---\")\n",
        "    print(f\"Mean TTFT:          {ttft_vals.mean():.4f} s\")\n",
        "    print(f\"Mean total latency: {lat_vals.mean():.4f} s\")\n",
        "    print(f\"P95 total latency:  {lat_vals.quantile(0.95):.4f} s\")\n",
        "    print(f\"Total throughput:   {len(df) / max_t:.2f} req/s\")\n",
        "\n",
        "\n",
        "# --- 4. VALIDATION (true M/M/1 check with CI) ---\n",
        "def run_mm1_validation():\n",
        "    print(\"\\n=== VALIDATION: M/M/1 COMPARISON ===\")\n",
        "\n",
        "    lam = 5.0\n",
        "    prompt_len = 100\n",
        "    decode_len = 1\n",
        "    total_tokens = prompt_len + decode_len\n",
        "\n",
        "    avg_service_time = (A_MARGINAL * total_tokens) / 1000.0\n",
        "    mu = 1.0 / avg_service_time\n",
        "\n",
        "    print(f\"Theory parameters: lambda = {lam:.2f} req/s, mu = {mu:.2f} req/s\")\n",
        "    if lam >= mu:\n",
        "        print(\"Warning: lambda >= mu, system unstable in M/M/1 theory.\")\n",
        "        return None\n",
        "\n",
        "    theo_response_time = 1.0 / (mu - lam)\n",
        "    print(f\"Expected mean response time (M/M/1): {theo_response_time:.4f} s\")\n",
        "\n",
        "    n_jobs = 20000\n",
        "    interarrivals = np.random.exponential(1.0 / lam, size=n_jobs)\n",
        "    arrival_times = np.cumsum(interarrivals)\n",
        "    service_times = np.random.exponential(1.0 / mu, size=n_jobs)\n",
        "\n",
        "    start_times = np.zeros(n_jobs)\n",
        "    finish_times = np.zeros(n_jobs)\n",
        "\n",
        "    last_finish = 0.0\n",
        "    for i in range(n_jobs):\n",
        "        start_times[i] = max(arrival_times[i], last_finish)\n",
        "        finish_times[i] = start_times[i] + service_times[i]\n",
        "        last_finish = finish_times[i]\n",
        "\n",
        "    completion_latency = finish_times - arrival_times\n",
        "\n",
        "    df_mm1 = pd.DataFrame({\n",
        "        \"arrival_time\": arrival_times,\n",
        "        \"service_time\": service_times,\n",
        "        \"start_time\": start_times,\n",
        "        \"completion_time\": finish_times,\n",
        "        \"completion_latency\": completion_latency,\n",
        "    })\n",
        "\n",
        "    lat_vals = df_mm1[\"completion_latency\"].dropna()\n",
        "    sim_mean_latency = lat_vals.mean()\n",
        "    sim_std_latency = lat_vals.std(ddof=1)\n",
        "    n = len(lat_vals)\n",
        "    se = sim_std_latency / np.sqrt(n)\n",
        "    ci_low = sim_mean_latency - 1.96 * se\n",
        "    ci_high = sim_mean_latency + 1.96 * se\n",
        "\n",
        "    print(f\"Simulated mean latency (N={n}): {sim_mean_latency:.4f} s\")\n",
        "    print(f\"95% CI for simulated mean: [{ci_low:.4f}, {ci_high:.4f}] s\")\n",
        "    print(\"=== VALIDATION COMPLETE ===\\n\")\n",
        "\n",
        "    return df_mm1\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# EXECUTE DEMO\n",
        "# ==========================================\n",
        "_ = run_mm1_validation()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjuKJmOJP9Wk",
        "outputId": "67ff62b6-e9d8-43a3-8b23-119365de1a2b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== VALIDATION: M/M/1 COMPARISON ===\n",
            "Theory parameters: lambda = 5.00 req/s, mu = 33.00 req/s\n",
            "Expected mean response time (M/M/1): 0.0357 s\n",
            "Simulated mean latency (N=20000): 0.0361 s\n",
            "95% CI for simulated mean: [0.0356, 0.0366] s\n",
            "=== VALIDATION COMPLETE ===\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block 5- Scheduling Policies and Tradeoffs\n",
        "\n",
        "In this section, we compare two simple scheduling policies on top of the same\n",
        "physics model (Poisson arrivals, Llama-style batch service time\n",
        "\\\\(S(b) = c + a \\max(0, b - b_0)\\\\)):\n",
        "\n",
        "1. **Process-to-Completion (P2C, no batching)**  \n",
        "   - The GPU always picks the earliest-arrived job from the queue and processes\n",
        "     it **alone** until its entire response is done.  \n",
        "   - This corresponds to a simple “each query runs to completion” baseline\n",
        "     without any batching or prefill/decode structure.\n",
        "   - Intuition: good for *simplicity*, but wastes GPU parallelism and tends\n",
        "     to have **poor throughput**.\n",
        "\n",
        "2. **Prefill-Prioritizing Batched Decode (PPB)**  \n",
        "   - Queries arrive over time and are collected into **batches** up to\n",
        "     `max_batch_size`.\n",
        "   - For each batch, we first run a **prefill phase** on all prompts in the\n",
        "     batch (prompt lengths \\\\(L_i\\\\)), then enter a **decode phase** where we\n",
        "     generate **one token per request per decode step** until all outputs\n",
        "     finish.\n",
        "   - All service is modeled through the same batch latency function\n",
        "     \\\\(S(b) = c + a \\max(0, b - b_0)\\\\), where \\\\(b\\\\) is the total token\n",
        "     load in the batch step.\n",
        "   - Intuition: exploits GPU parallelism, so **throughput** is higher.\n",
        "     However, batching and prefill phases can increase TTFT for some users.\n",
        "\n",
        "For a clean apples-to-apples comparison, we consider a simple homogeneous\n",
        "setting:\n",
        "\n",
        "- Single GPU worker\n",
        "- Single job type:\n",
        "  - Prompt length \\\\(L = L_0\\\\) (fixed)\n",
        "  - Output length \\\\(B = B_0\\\\) (fixed)\n",
        "- Poisson arrivals with rate \\\\(\\lambda\\\\)\n",
        "- Same service-time physics \\\\(S(b)\\\\) used in earlier sections.\n",
        "\n",
        "We measure, for each policy and arrival rate \\\\(\\lambda\\\\):\n",
        "\n",
        "- **TTFT** (Time to First Token)\n",
        "- **Total latency** (completion time – arrival time)\n",
        "- **Average TBT** (time between output tokens)\n",
        "- **Throughput** in completed requests / second\n",
        "\n",
        "Below we define a lightweight simulator for these two policies and then run\n",
        "experiments across a grid of arrival rates."
      ],
      "metadata": {
        "id": "e6Ys8h9tPaka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch service time S(b) in seconds for a batch with `batch_token_load` tokens.\n",
        "def batch_service_time_seconds(batch_token_load):\n",
        "    \"\"\"Calculates processing time in SECONDS.\"\"\"\n",
        "    ms_time = C_SETUP + A_MARGINAL * max(0, batch_token_load - B0_THRESHOLD)\n",
        "    return ms_time / 1000.0  # convert milliseconds -> seconds\n",
        "\n",
        "@dataclass\n",
        "class SimpleRequest:\n",
        "    req_id: int\n",
        "    arrival_time: float\n",
        "    prompt_len: int\n",
        "    output_len: int\n",
        "    first_token_time: float | None = None\n",
        "    finish_time: float | None = None\n",
        "    decoded_tokens: int = 0\n",
        "\n",
        "\n",
        "def generate_homogeneous_requests(\n",
        "    lam: float,\n",
        "    num_jobs: int,\n",
        "    prompt_len: int,\n",
        "    output_len: int,\n",
        "    seed: int | None = None,\n",
        ") -> list[SimpleRequest]:\n",
        "    \"\"\"\n",
        "    Generate `num_jobs` Poisson arrivals with rate lam, all with the same\n",
        "    prompt_len and output_len.\n",
        "    \"\"\"\n",
        "    rng = random.Random(seed)\n",
        "    t = 0.0\n",
        "    requests: list[SimpleRequest] = []\n",
        "    for j in range(num_jobs):\n",
        "      t += rng.expovariate(lam)\n",
        "      requests.append(SimpleRequest(j, t, prompt_len, output_len))\n",
        "    return requests\n",
        "\n",
        "\n",
        "# -------------------- Policy 1: Process-to-Completion (P2C) --------------------\n",
        "\n",
        "def simulate_p2c(\n",
        "    lam: float,\n",
        "    num_jobs: int,\n",
        "    prompt_len: int,\n",
        "    output_len: int,\n",
        "    seed: int | None = None,\n",
        ") -> tuple[pd.DataFrame, float]:\n",
        "    \"\"\"\n",
        "    Single-server FCFS system.\n",
        "    Each request runs to completion alone; modeled as a single batch\n",
        "    with token load L + B.\n",
        "\n",
        "    Returns:\n",
        "        df: per-request metrics\n",
        "        sim_length: total simulated time (last_finish - first_arrival)\n",
        "    \"\"\"\n",
        "    requests = generate_homogeneous_requests(\n",
        "        lam=lam,\n",
        "        num_jobs=num_jobs,\n",
        "        prompt_len=prompt_len,\n",
        "        output_len=output_len,\n",
        "        seed=seed,\n",
        "    )\n",
        "    if not requests:\n",
        "        return pd.DataFrame(), 0.0\n",
        "\n",
        "    server_free_time = 0.0\n",
        "    first_arrival = requests[0].arrival_time\n",
        "    last_finish = first_arrival\n",
        "\n",
        "    for r in requests:\n",
        "        start_service = max(r.arrival_time, server_free_time)\n",
        "        total_tokens = r.prompt_len + r.output_len\n",
        "        service_time = batch_service_time_seconds(total_tokens)\n",
        "\n",
        "        # Heuristic: TTFT = time to \"prefill\" the prompt fraction\n",
        "        prefill_time = service_time * (r.prompt_len / total_tokens)\n",
        "        r.first_token_time = start_service + prefill_time\n",
        "\n",
        "        r.finish_time = start_service + service_time\n",
        "        r.decoded_tokens = r.output_len\n",
        "\n",
        "        server_free_time = r.finish_time\n",
        "        last_finish = max(last_finish, r.finish_time)\n",
        "\n",
        "    sim_length = max(last_finish - first_arrival, 1e-9)\n",
        "\n",
        "    rows = []\n",
        "    for r in requests:\n",
        "        ttft = r.first_token_time - r.arrival_time\n",
        "        latency = r.finish_time - r.arrival_time\n",
        "\n",
        "        # Make avg_TBT definition consistent with PPB:\n",
        "        # total decode duration / (output_len - 1)\n",
        "        if r.output_len > 1:\n",
        "            avg_tbt = (r.finish_time - r.first_token_time) / (r.output_len - 1)\n",
        "        else:\n",
        "            avg_tbt = 0.0\n",
        "\n",
        "        rows.append(\n",
        "            {\n",
        "                \"policy\": \"P2C\",\n",
        "                \"req_id\": r.req_id,\n",
        "                \"arrival\": r.arrival_time,\n",
        "                \"TTFT\": ttft,\n",
        "                \"Latency\": latency,\n",
        "                \"avg_TBT\": avg_tbt,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df, sim_length\n",
        "\n",
        "# -------- Policy 2: Prefill-Prioritizing Batched Decode (PPB) --------\n",
        "\n",
        "def simulate_ppb(\n",
        "    lam: float,\n",
        "    num_jobs: int,\n",
        "    prompt_len: int,\n",
        "    output_len: int,\n",
        "    max_batch_size: int = 8,\n",
        "    seed: int | None = None,\n",
        ") -> tuple[pd.DataFrame, float]:\n",
        "    \"\"\"\n",
        "    Prefill-prioritizing batched decode (Discrete Event Simulation).\n",
        "    \"\"\"\n",
        "    rng = random.Random(seed)\n",
        "    requests = generate_homogeneous_requests(\n",
        "        lam=lam,\n",
        "        num_jobs=num_jobs,\n",
        "        prompt_len=prompt_len,\n",
        "        output_len=output_len,\n",
        "        seed=seed,\n",
        "    )\n",
        "    if not requests:\n",
        "        return pd.DataFrame(), 0.0\n",
        "\n",
        "    t = 0.0\n",
        "    arrival_index = 0\n",
        "    N = len(requests)\n",
        "\n",
        "    # State tracking\n",
        "    prefill_queue: list[SimpleRequest] = []\n",
        "    decode_jobs: list[SimpleRequest] = []\n",
        "\n",
        "    first_arrival = requests[0].arrival_time\n",
        "    last_finish = first_arrival\n",
        "\n",
        "    while arrival_index < N or prefill_queue or decode_jobs:\n",
        "\n",
        "        # 1. Idle jump / Admit arrivals\n",
        "        if not prefill_queue and not decode_jobs and arrival_index < N:\n",
        "            t = max(t, requests[arrival_index].arrival_time)\n",
        "\n",
        "        # Admit all arrivals that have occurred up to the current time t\n",
        "        while (arrival_index < N and requests[arrival_index].arrival_time <= t):\n",
        "            prefill_queue.append(requests[arrival_index])\n",
        "            arrival_index += 1\n",
        "\n",
        "        # Check termination condition\n",
        "        if not prefill_queue and not decode_jobs and arrival_index >= N:\n",
        "            break\n",
        "\n",
        "        # If both queues are empty, but more arrivals are scheduled (t < max_duration equivalent in the grid run)\n",
        "        if not prefill_queue and not decode_jobs and arrival_index < N:\n",
        "            continue\n",
        "\n",
        "        # 2. Scheduling Logic (Prioritize Prefill)\n",
        "        if prefill_queue:\n",
        "            # --- PREFILL PHASE ---\n",
        "            # Max K requests can be prefills at a time (implicit batch size K)\n",
        "            batch = prefill_queue[:max_batch_size]\n",
        "            prefill_queue = prefill_queue[max_batch_size:]\n",
        "\n",
        "            batch_tokens = sum(r.prompt_len for r in batch)\n",
        "            step_time = batch_service_time_seconds(batch_tokens)\n",
        "\n",
        "            t += step_time\n",
        "\n",
        "            for r in batch:\n",
        "                r.decoded_tokens = 1 # First token generated\n",
        "                if r.first_token_time is None:\n",
        "                     r.first_token_time = t\n",
        "                # Move request to the decode pool\n",
        "                decode_jobs.append(r)\n",
        "\n",
        "            # Since prefill is prioritized, we loop back to check if we can run another prefill batch\n",
        "            continue\n",
        "\n",
        "        # 3. DECODE phase (only runs if prefill_queue is empty)\n",
        "        if decode_jobs:\n",
        "            # Active jobs are those that are not yet complete\n",
        "            active = [r for r in decode_jobs if r.decoded_tokens < r.output_len]\n",
        "            if not active:\n",
        "                decode_jobs = [] # Clean up the list\n",
        "                continue\n",
        "\n",
        "            # Batch up to max_batch_size decode jobs (1 token per job)\n",
        "            active_batch = active[:max_batch_size]\n",
        "            batch_tokens = len(active_batch)\n",
        "\n",
        "            step_time = batch_service_time_seconds(batch_tokens)\n",
        "            t += step_time\n",
        "\n",
        "            # Generate one token for each request in the active batch\n",
        "            for r in active_batch:\n",
        "                r.decoded_tokens += 1\n",
        "                if r.decoded_tokens >= r.output_len and r.finish_time is None:\n",
        "                    r.finish_time = t\n",
        "                    last_finish = max(last_finish, t)\n",
        "\n",
        "            # Update decode_jobs list to keep only incomplete jobs\n",
        "            decode_jobs = [r for r in decode_jobs if r.finish_time is None]\n",
        "\n",
        "            # Loop back to check for prefill work before next decode step\n",
        "            continue\n",
        "\n",
        "    sim_length = max(last_finish - first_arrival, 1e-9)\n",
        "\n",
        "    rows = []\n",
        "    for r in requests:\n",
        "        if r.finish_time is None or r.first_token_time is None:\n",
        "            continue\n",
        "        ttft = r.first_token_time - r.arrival_time\n",
        "        latency = r.finish_time - r.arrival_time\n",
        "\n",
        "        # Avg TBT: total decode time / (output_budget - 1)\n",
        "        if r.output_len > 1:\n",
        "            # Calculate total decode duration: (finish_time - first_token_time)\n",
        "            avg_tbt = (r.finish_time - r.first_token_time) / (r.output_len - 1)\n",
        "        else:\n",
        "            avg_tbt = 0.0\n",
        "\n",
        "        rows.append(\n",
        "            {\n",
        "                \"policy\": \"PPB\",\n",
        "                \"req_id\": r.req_id,\n",
        "                \"arrival\": r.arrival_time,\n",
        "                \"TTFT\": ttft,\n",
        "                \"Latency\": latency,\n",
        "                \"avg_TBT\": avg_tbt,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df, sim_length\n",
        "\n",
        "def run_policy_grid(\n",
        "    lambdas: list[float],\n",
        "    num_jobs: int = 2000,\n",
        "    prompt_len: int = 100,\n",
        "    output_len: int = 16,\n",
        "    max_batch_size: int = 8,\n",
        "    seed: int = 123,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    For each λ, run P2C and PPB, collect summary metrics.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for lam in lambdas:\n",
        "        # ensure different seeds per λ but reproducible\n",
        "        seed_p2c = seed + int(1000 * lam)\n",
        "        seed_ppb = seed + int(2000 * lam)\n",
        "\n",
        "        df_p2c, len_p2c = simulate_p2c(\n",
        "            lam=lam,\n",
        "            num_jobs=num_jobs,\n",
        "            prompt_len=prompt_len,\n",
        "            output_len=output_len,\n",
        "            seed=seed_p2c,\n",
        "        )\n",
        "        df_ppb, len_ppb = simulate_ppb(\n",
        "            lam=lam,\n",
        "            num_jobs=num_jobs,\n",
        "            prompt_len=prompt_len,\n",
        "            output_len=output_len,\n",
        "            max_batch_size=max_batch_size,\n",
        "            seed=seed_ppb,\n",
        "        )\n",
        "\n",
        "        for name, df, sim_len in [\n",
        "            (\"P2C\", df_p2c, len_p2c),\n",
        "            (\"PPB\", df_ppb, len_ppb),\n",
        "        ]:\n",
        "            if df.empty or sim_len <= 0 or len(df) < num_jobs * 0.5:\n",
        "                continue\n",
        "\n",
        "            mean_ttft = df[\"TTFT\"].mean()\n",
        "            p95_ttft = df[\"TTFT\"].quantile(0.95)\n",
        "            mean_lat = df[\"Latency\"].mean()\n",
        "            p95_lat = df[\"Latency\"].quantile(0.95)\n",
        "            mean_tbt = df[\"avg_TBT\"].mean()\n",
        "            throughput = len(df) / sim_len\n",
        "\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"lambda\": lam,\n",
        "                    \"policy\": name,\n",
        "                    \"mean_TTFT\": mean_ttft,\n",
        "                    \"p95_TTFT\": p95_ttft,\n",
        "                    \"mean_Latency\": mean_lat,\n",
        "                    \"p95_Latency\": p95_lat,\n",
        "                    \"mean_avg_TBT\": mean_tbt,\n",
        "                    \"Throughput\": throughput,\n",
        "                    \"num_completed\": len(df),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def plot_policy_comparison(summary_df: pd.DataFrame) -> None:\n",
        "    if summary_df.empty:\n",
        "        print(\"No data to plot.\")\n",
        "        return\n",
        "\n",
        "    policies = sorted(summary_df[\"policy\"].unique())\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
        "\n",
        "    # ------------------ Plot 1: Mean TTFT (Latency until first token) ------------------\n",
        "    ax = axes[0]\n",
        "    for pol in policies:\n",
        "        sub = summary_df[summary_df[\"policy\"] == pol]\n",
        "        ax.plot(sub[\"lambda\"], sub[\"mean_TTFT\"], marker=\"o\", label=pol)\n",
        "    ax.set_xlabel(\"Arrival rate $\\lambda$ (req/s)\")\n",
        "    ax.set_ylabel(\"Mean TTFT (s)\")\n",
        "    ax.set_title(\"Mean Time To First Token (TTFT)\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # ------------------ Plot 2: Mean Latency (Total response time) ------------------\n",
        "    ax = axes[1]\n",
        "    for pol in policies:\n",
        "        sub = summary_df[summary_df[\"policy\"] == pol]\n",
        "        ax.plot(sub[\"lambda\"], sub[\"mean_Latency\"], marker=\"o\", label=pol)\n",
        "    ax.set_xlabel(\"Arrival rate $\\lambda$ (req/s)\")\n",
        "    ax.set_ylabel(\"Mean Total Latency (s)\")\n",
        "    ax.set_title(\"Mean Total Latency (E[T])\")\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # ------------------ Plot 3: Throughput ------------------\n",
        "    ax = axes[2]\n",
        "    for pol in policies:\n",
        "        sub = summary_df[summary_df[\"policy\"] == pol]\n",
        "        ax.plot(sub[\"lambda\"], sub[\"Throughput\"], marker=\"o\", label=pol)\n",
        "    ax.set_xlabel(\"Arrival rate $\\lambda$ (req/s)\")\n",
        "    ax.set_ylabel(\"Throughput (completed req/s)\")\n",
        "    ax.set_title(\"Achieved Throughput\")\n",
        "    # Add a line for the offered load (lambda) for comparison\n",
        "    ax.plot(summary_df[\"lambda\"].unique(), summary_df[\"lambda\"].unique(), linestyle=':', color='gray', label='Offered Load ($\\lambda$)')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('policy_comparison_tradeoffs.png') # Saving the figure\n",
        "\n",
        "# ------------------------ Run the comparison demo ------------------------\n",
        "\n",
        "lambdas = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
        "summary_df = run_policy_grid(\n",
        "    lambdas=lambdas,\n",
        "    num_jobs=2000,\n",
        "    prompt_len=100,\n",
        "    output_len=16,\n",
        "    max_batch_size=8,\n",
        "    seed=123,\n",
        ")\n",
        "\n",
        "# Save the results to CSV\n",
        "summary_df.round(4).to_csv('policy_comparison_summary.csv', index=False)\n",
        "\n",
        "# The console output will show the summary table.\n",
        "print(\"=== Policy Comparison Summary (policy_comparison_summary.csv) ===\")\n",
        "print(summary_df.round(4).to_string(index=False))\n",
        "\n",
        "plot_policy_comparison(summary_df)"
      ],
      "metadata": {
        "id": "tgYu9RKCf48J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simulation highlights a clear performance tradeoff between the **Process-to-Completion (P2C)** baseline and the **Prefill-Prioritizing Batched Decode (PPB)** scheduler.\n",
        "\n",
        "1. Time To First Token (TTFT)\n",
        "PPB consistently shows higher TTFT than P2C across all arrival rates.  \n",
        "Because PPB waits for a prefill batch to form before issuing the first token, requests experience an additional batching delay.  \n",
        "P2C, which begins serving each request immediately, produces the lowest TTFT.\n",
        "\n",
        "2. Total Latency\n",
        "PPB also yields higher total latency. Even though decode steps are batched, each request must:\n",
        "- wait for a global prefill batch,\n",
        "- share decode cycles with other jobs,\n",
        "- and complete its output tokens over multiple synchronized decode rounds.\n",
        "\n",
        "P2C avoids these queueing layers by dedicating the GPU to a single request at a time, resulting in consistently lower end-to-end latency.\n",
        "\n",
        "3. Throughput\n",
        "Throughput for both policies closely matches the offered load $$\\lambda$$, indicating that:\n",
        "- the GPU is not saturated under this workload,\n",
        "- batching does not provide additional throughput benefits,\n",
        "- and both schedulers remain work-conserving up to the tested arrival rates.\n",
        "\n",
        "- **P2C minimizes TTFT and total latency**, making it preferable for interactive applications where responsiveness matters.\n",
        "- **PPB trades latency for batching structure**, but under homogeneous request sizes and moderate load, this batching does not meaningfully improve throughput.\n",
        "- Because throughput remains roughly $$\\text{Throughput} \\approx \\lambda$$ for both policies, the main difference lies in latency behavior, not capacity.\n",
        "\n",
        "In summary, batching does not significantly increase throughput in this workload but does introduce noticeable delays, making P2C the more latency-efficient scheduling strategy.\n"
      ],
      "metadata": {
        "id": "PDLNBITHlYn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Block 6- Validation: M/M/1 without Batching\n",
        "\n",
        "To validate that our event-driven simulator is consistent with classical\n",
        "queueing theory, we consider a **simplified** setting:\n",
        "\n",
        "- Single server, FCFS\n",
        "- Poisson arrivals with rate \\\\(\\lambda\\\\)\n",
        "- Exponential service times with rate \\\\(\\mu\\\\)\n",
        "- No batching, no setup time, and no prefill/decode structure\n",
        "\n",
        "This is exactly an **M/M/1 queue**. In steady state (for \\\\(\\lambda < \\mu\\\\)),\n",
        "the mean response time is\n",
        "\n",
        "\\\\[\n",
        "\\mathbb{E}[T] = \\frac{1}{\\mu - \\lambda}.\n",
        "\\\\]\n",
        "\n",
        "We implement a minimal simulator for this setting and compare:\n",
        "\n",
        "- Theoretical mean response time \\\\(1 / (\\mu - \\lambda)\\\\)\n",
        "- Simulated mean response time (from many requests)\n",
        "\n",
        "We also vary \\\\(\\lambda\\\\) for a fixed \\\\(\\mu\\\\) to show that the simulated\n",
        "curve tracks the theoretical curve and diverges as \\\\(\\lambda\\\\) approaches\n",
        "\\\\(\\mu\\\\), matching the standard M/M/1 behavior.\n"
      ],
      "metadata": {
        "id": "Kl7CWS4CYl0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_mm1(\n",
        "    lam: float,\n",
        "    mu: float,\n",
        "    num_jobs: int = 5000,\n",
        "    seed: Optional[int] = None,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Simple M/M/1 FCFS simulation:\n",
        "      - Arrivals ~ Poisson process with rate lam\n",
        "      - Service times ~ Exp(mu)\n",
        "    Returns the sample mean response time (sojourn time).\n",
        "    \"\"\"\n",
        "    rng = random.Random(seed)\n",
        "\n",
        "    arrival_times = []\n",
        "    t = 0.0\n",
        "    for _ in range(num_jobs):\n",
        "        t += rng.expovariate(lam)  # interarrival\n",
        "        arrival_times.append(t)\n",
        "\n",
        "    # Process jobs in order\n",
        "    server_free_time = 0.0\n",
        "    response_times = []\n",
        "\n",
        "    for a in arrival_times:\n",
        "        start_service = max(a, server_free_time)\n",
        "        service_time = rng.expovariate(mu)\n",
        "        finish_time = start_service + service_time\n",
        "        server_free_time = finish_time\n",
        "        response_times.append(finish_time - a)\n",
        "\n",
        "    return float(np.mean(response_times))\n",
        "\n",
        "\n",
        "def run_mm1_validation_demo(\n",
        "    lam: float = 5.0,\n",
        "    mu: float = 8.0,\n",
        "    num_jobs: int = 5000,\n",
        "    seed: int = 42,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Print a simple side-by-side comparison of theory vs simulation\n",
        "    for a single (lam, mu) pair.\n",
        "    \"\"\"\n",
        "    if lam >= mu:\n",
        "        print(\"Warning: For M/M/1 we require λ < μ for a stable system.\")\n",
        "    theo = 1.0 / (mu - lam)\n",
        "    sim = simulate_mm1(lam=lam, mu=mu, num_jobs=num_jobs, seed=seed)\n",
        "\n",
        "    print(\"=== M/M/1 Validation (Single Point) ===\")\n",
        "    print(f\"lambda (arrival rate): {lam:.2f}\")\n",
        "    print(f\"mu     (service rate): {mu:.2f}\")\n",
        "    print(f\"Theoretical E[T]: {theo:.4f} s\")\n",
        "    print(f\"Simulated  E[T]: {sim:.4f} s\")\n",
        "\n",
        "\n",
        "def sweep_mm1_vs_lambda(\n",
        "    mu: float = 8.0,\n",
        "    lam_values: Optional[List[float]] = None,\n",
        "    num_jobs: int = 3000,\n",
        "    seed: int = 123,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Sweep over a set of lambda values and compare theory vs simulated\n",
        "    mean response time.\n",
        "    \"\"\"\n",
        "    if lam_values is None:\n",
        "        lam_values = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]  # all < mu\n",
        "\n",
        "    rows = []\n",
        "    for lam in lam_values:\n",
        "        theo = 1.0 / (mu - lam)\n",
        "        sim = simulate_mm1(lam=lam, mu=mu, num_jobs=num_jobs, seed=seed)\n",
        "        rows.append(\n",
        "            {\n",
        "                \"lambda\": lam,\n",
        "                \"mu\": mu,\n",
        "                \"theoretical_E_T\": theo,\n",
        "                \"simulated_E_T\": sim,\n",
        "            }\n",
        "        )\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "def plot_mm1_validation(df: pd.DataFrame) -> None:\n",
        "    if df.empty:\n",
        "        print(\"No data for M/M/1 validation.\")\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(df[\"lambda\"], df[\"theoretical_E_T\"], marker=\"o\", label=\"Theory 1/(μ-λ)\")\n",
        "    plt.plot(df[\"lambda\"], df[\"simulated_E_T\"], marker=\"x\", linestyle=\"--\", label=\"Simulation\")\n",
        "    plt.xlabel(\"λ (arrival rate)\")\n",
        "    plt.ylabel(\"Mean response time E[T] (s)\")\n",
        "    plt.title(\"M/M/1: Theory vs Simulation\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# --- Run the validation demo ---\n",
        "\n",
        "run_mm1_validation_demo(lam=5.0, mu=8.0, num_jobs=5000, seed=42)\n",
        "\n",
        "df_mm1 = sweep_mm1_vs_lambda(mu=8.0, lam_values=[1, 2, 3, 4, 5, 6], num_jobs=4000, seed=123)\n",
        "print(\"\\n=== M/M/1 Sweep Summary ===\")\n",
        "print(df_mm1.round(4))\n",
        "\n",
        "plot_mm1_validation(df_mm1)\n"
      ],
      "metadata": {
        "id": "1O08dNXqTkOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The M/M/1 experiment validates that the discrete-event simulator behaves correctly\n",
        "under a setting with known closed-form queueing dynamics. For an M/M/1 queue with\n",
        "arrival rate $\\lambda$ and service rate $\\mu$, the theoretical mean response time is\n",
        "\n",
        "$$\n",
        "E[T] = \\frac{1}{\\mu - \\lambda}.\n",
        "$$\n",
        "\n",
        "Across all tested arrival rates, the simulated mean sojourn times closely match the\n",
        "theoretical curve. The agreement is strongest when the system is lightly loaded\n",
        "(large $\\mu - \\lambda$), and small deviations appear as $\\lambda$ approaches $\\mu$, where\n",
        "the queue becomes more sensitive to stochastic variation. This behavior is expected\n",
        "because response times grow rapidly near saturation.\n",
        "\n",
        "Overall, the results confirm that:\n",
        "\n",
        "- the Poisson arrival generator is producing correct interarrival intervals,\n",
        "- exponential service times yield the correct utilization patterns,\n",
        "- the FCFS server discipline is implemented properly, and\n",
        "- the event-driven simulation tracks queue buildup and service completion\n",
        "  in accordance with classical M/M/1 theory.\n",
        "\n",
        "Because the simulated curve tracks the theoretical curve extremely well, we can be\n",
        "confident that the core timing and queueing logic used in the full GPU scheduling\n",
        "simulation is correct.\n"
      ],
      "metadata": {
        "id": "7eao6OHsmcJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block 6: Steady-State Estimation (Simulation)\n",
        "\n",
        "### Goal\n",
        "Estimate **steady-state** performance metrics from the simulator by removing warm-up bias and summarizing long-run behavior with statistically stable estimates.\n",
        "\n",
        "---\n",
        "\n",
        "### Key Outputs\n",
        "- `mean_wait_ss`: steady-state mean waiting time (or your primary KPI)\n",
        "- `mean_system_ss`: steady-state mean time-in-system (if tracked)\n",
        "- `utilization_est`: estimated utilization `rho` (if computed)\n",
        "- `ci_95`: 95% confidence interval for the steady-state mean (batch means)\n",
        "- `n_effective`: number of post–warm-up observations used\n",
        "\n",
        "---\n",
        "\n",
        "### Inputs / Parameters\n",
        "- `seed`: RNG seed for reproducibility\n",
        "- `T_max` or `N_max`: total run length (time horizon or number of customers/jobs)\n",
        "- `warmup_rule`: warm-up removal approach  \n",
        "  - example: fixed fraction `warmup_frac` (e.g., 0.2)  \n",
        "  - or fixed count `warmup_N`  \n",
        "  - or stability-based cutoff\n",
        "- `batch_size` (`m`): number of observations per batch (post–warm-up)\n",
        "- `n_batches` (`b`): number of batches\n",
        "- `metric_series`: time series collected from the sim (e.g., `wait_times`, `system_times`, `queue_lengths`)\n",
        "\n",
        "---\n",
        "\n",
        "### Procedure (What the code does)\n",
        "\n",
        "#### 1) Run a long simulation\n",
        "- Simulate until reaching `T_max` (time-based) **or** `N_max` (event-based).\n",
        "- Collect per-customer (or per-event) metrics into arrays:\n",
        "  - `W[i]` = waiting time for job `i`\n",
        "  - `S[i]` = system time for job `i` (optional)\n",
        "  - `Q(t)` or sampled queue lengths (optional)\n",
        "\n",
        "#### 2) Remove warm-up (transient) period\n",
        "Goal: avoid bias from the empty-system start.\n",
        "\n",
        "Typical implementation in code:\n",
        "- Determine cutoff index `k`:\n",
        "  - `k = floor(warmup_frac * len(W))`  **or**\n",
        "  - `k = warmup_N`\n",
        "- Keep post–warm-up data:\n",
        "  - `W_ss = W[k:]`\n",
        "  - `S_ss = S[k:]` (if used)\n",
        "\n",
        "Sanity checks:\n",
        "- Ensure `len(W_ss) >= batch_size * n_batches`\n",
        "- If not, increase `T_max/N_max` or reduce batching requirements.\n",
        "\n",
        "#### 3) Batch means for steady-state mean + CI\n",
        "Assume `W_ss` is correlated; batching reduces correlation.\n",
        "\n",
        "- Partition `W_ss` into `b` consecutive batches of size `m`:\n",
        "  - Batch `j` contains `W_ss[(j*m) : ((j+1)*m)]`\n",
        "- Compute batch means:\n",
        "  - `Y_j = mean(batch_j)` for `j = 1..b`\n",
        "- Steady-state mean estimate:\n",
        "  - `mean_wait_ss = mean(Y_1..Y_b)`\n",
        "- Sample variance of batch means:\n",
        "  - `s_Y^2 = (1/(b-1)) * sum((Y_j - mean_wait_ss)^2)`\n",
        "- Standard error:\n",
        "  - `SE = sqrt(s_Y^2 / b)`\n",
        "- 95% CI (two-sided):\n",
        "  - `t = t_{0.975, df=b-1}`\n",
        "  - `CI = mean_wait_ss ± t * SE`\n",
        "\n",
        "Reported fields in code typically include:\n",
        "- `mean_wait_ss`\n",
        "- `ci_low`, `ci_high`\n",
        "- `SE`\n",
        "- `b`, `m`, and `k`\n",
        "\n",
        "#### 4) Optional convergence / stability checks (if included)\n",
        "Common checks used in steady-state code:\n",
        "- **Batch-mean stability**: stop when CI half-width is below tolerance:\n",
        "  - `half_width = t * SE`\n",
        "  - require `half_width <= eps_abs` or `half_width/mean <= eps_rel`\n",
        "- **Rolling mean stabilization**: verify `rolling_mean` changes are small after a point\n",
        "- **Minimum run constraints**: enforce `b >= 20` (typical) for reasonable t-based CI\n",
        "\n",
        "---\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(N)` per replication (plus constant-time batching)\n",
        "- Memory: `O(N)` if storing full series; can be reduced to `O(b*m)` or streaming batch accumulation.\n",
        "\n",
        "---\n",
        "\n",
        "### Assumptions / Limitations\n",
        "- Batch means CI assumes batch means are approximately independent and normal (improves with larger `m` and `b`).\n",
        "- Warm-up removal is heuristic unless using a formal method (e.g., MSER, Welch); fixed warm-up may under/over-trim.\n",
        "- If traffic intensity is near 1 (heavy load), mixing is slow; requires larger `T_max/N_max` and larger batch sizes.\n",
        "\n",
        "---\n",
        "\n",
        "### Reproducibility Notes\n",
        "- Always record: `seed`, warm-up cutoff `k`, `batch_size m`, `n_batches b`, total run length `T_max/N_max`.\n",
        "- If running multiple replications, aggregate replication-level steady-state means and report overall mean + CI across replications.\n"
      ],
      "metadata": {
        "id": "VO7ZF5VXeG36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STEADY-STATE / WARM-UP / REPLICATIONS BLOCK\n",
        "# ==============================\n",
        "\n",
        "def summarize_single_run(df: pd.DataFrame, warmup_jobs: int) -> dict | None:\n",
        "    \"\"\"\n",
        "    Take a per-request DataFrame from simulate_p2c / simulate_ppb,\n",
        "    discard the first `warmup_jobs` by arrival time, and compute\n",
        "    steady-state metrics.\n",
        "\n",
        "    Returns a dict of summary metrics for this single run, or None\n",
        "    if not enough jobs survived warm-up.\n",
        "    \"\"\"\n",
        "    if df.empty or len(df) <= warmup_jobs:\n",
        "        return None\n",
        "\n",
        "    # Sort by arrival, drop warm-up jobs\n",
        "    df_sorted = df.sort_values(\"arrival\").reset_index(drop=True)\n",
        "    df_ss = df_sorted.iloc[warmup_jobs:].copy()\n",
        "    if df_ss.empty:\n",
        "        return None\n",
        "\n",
        "    # Reconstruct finish times from arrival + latency\n",
        "    finish_times = df_ss[\"arrival\"] + df_ss[\"Latency\"]\n",
        "    first_arrival_ss = df_ss[\"arrival\"].min()\n",
        "    last_finish_ss = finish_times.max()\n",
        "    sim_len_ss = max(last_finish_ss - first_arrival_ss, 1e-9)\n",
        "\n",
        "    # Core metrics\n",
        "    mean_ttft = df_ss[\"TTFT\"].mean()\n",
        "    p95_ttft = df_ss[\"TTFT\"].quantile(0.95)\n",
        "    mean_lat = df_ss[\"Latency\"].mean()\n",
        "    p95_lat = df_ss[\"Latency\"].quantile(0.95)\n",
        "    mean_tbt = df_ss[\"avg_TBT\"].mean()\n",
        "    throughput = len(df_ss) / sim_len_ss  # completed jobs per second\n",
        "\n",
        "    return {\n",
        "        \"mean_TTFT\": mean_ttft,\n",
        "        \"p95_TTFT\": p95_ttft,\n",
        "        \"mean_Latency\": mean_lat,\n",
        "        \"p95_Latency\": p95_lat,\n",
        "        \"mean_avg_TBT\": mean_tbt,\n",
        "        \"Throughput\": throughput,\n",
        "        \"num_completed\": len(df_ss),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_policy_grid_with_replications(\n",
        "    lambdas: list[float],\n",
        "    num_jobs_total: int = 12000,\n",
        "    warmup_jobs: int = 2000,\n",
        "    prompt_len: int = 100,\n",
        "    output_len: int = 16,\n",
        "    max_batch_size: int = 8,\n",
        "    n_rep: int = 10,\n",
        "    seed: int = 123,\n",
        ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    For each λ and each policy (P2C, PPB), run `n_rep` independent\n",
        "    replications, each with `num_jobs_total` jobs.\n",
        "\n",
        "    For each replication:\n",
        "      - Drop the first `warmup_jobs` arrivals (warm-up),\n",
        "      - Compute steady-state metrics on the remaining jobs.\n",
        "\n",
        "    Returns:\n",
        "      per_rep_df: one row per (λ, policy, rep) with steady-state metrics\n",
        "      summary_df: aggregated means and 95% CIs across replications\n",
        "    \"\"\"\n",
        "    per_rep_rows = []\n",
        "\n",
        "    for lam in lambdas:\n",
        "        for policy_name, sim_fun, extra_kwargs in [\n",
        "            (\"P2C\", simulate_p2c, {}),\n",
        "            (\"PPB\", simulate_ppb, {\"max_batch_size\": max_batch_size}),\n",
        "        ]:\n",
        "            for rep in range(n_rep):\n",
        "                # Different seeds per (λ, policy, rep) but reproducible\n",
        "                run_seed = seed + int(1000 * lam) + 100 * (0 if policy_name == \"P2C\" else 1) + rep\n",
        "\n",
        "                # Run one replication\n",
        "                if policy_name == \"P2C\":\n",
        "                    df_run, sim_len = sim_fun(\n",
        "                        lam=lam,\n",
        "                        num_jobs=num_jobs_total,\n",
        "                        prompt_len=prompt_len,\n",
        "                        output_len=output_len,\n",
        "                        seed=run_seed,\n",
        "                    )\n",
        "                else:\n",
        "                    df_run, sim_len = sim_fun(\n",
        "                        lam=lam,\n",
        "                        num_jobs=num_jobs_total,\n",
        "                        prompt_len=prompt_len,\n",
        "                        output_len=output_len,\n",
        "                        seed=run_seed,\n",
        "                        **extra_kwargs,\n",
        "                    )\n",
        "\n",
        "                if df_run.empty or sim_len <= 0:\n",
        "                    continue\n",
        "\n",
        "                # Summarize steady-state portion\n",
        "                metrics = summarize_single_run(df_run, warmup_jobs=warmup_jobs)\n",
        "                if metrics is None:\n",
        "                    continue\n",
        "\n",
        "                metrics.update(\n",
        "                    {\n",
        "                        \"lambda\": lam,\n",
        "                        \"policy\": policy_name,\n",
        "                        \"rep\": rep,\n",
        "                    }\n",
        "                )\n",
        "                per_rep_rows.append(metrics)\n",
        "\n",
        "    per_rep_df = pd.DataFrame(per_rep_rows)\n",
        "    if per_rep_df.empty:\n",
        "        print(\"No data from replications.\")\n",
        "        return per_rep_df, pd.DataFrame()\n",
        "\n",
        "    # Aggregate across replications: mean + 95% CI\n",
        "    summary_rows = []\n",
        "    metric_cols = [\n",
        "        \"mean_TTFT\",\n",
        "        \"p95_TTFT\",\n",
        "        \"mean_Latency\",\n",
        "        \"p95_Latency\",\n",
        "        \"mean_avg_TBT\",\n",
        "        \"Throughput\",\n",
        "    ]\n",
        "\n",
        "    for (lam, pol), sub in per_rep_df.groupby([\"lambda\", \"policy\"]):\n",
        "        row = {\"lambda\": lam, \"policy\": pol}\n",
        "        n = len(sub)\n",
        "        for col in metric_cols:\n",
        "            m = sub[col].mean()\n",
        "            s = sub[col].std(ddof=1) if n > 1 else 0.0\n",
        "            ci_half = 1.96 * s / np.sqrt(n) if n > 1 else 0.0\n",
        "            row[col] = m\n",
        "            row[col + \"_CI_low\"] = m - ci_half\n",
        "            row[col + \"_CI_high\"] = m + ci_half\n",
        "        row[\"num_completed_mean\"] = sub[\"num_completed\"].mean()\n",
        "        summary_rows.append(row)\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_rows).sort_values([\"lambda\", \"policy\"]).reset_index(drop=True)\n",
        "    return per_rep_df, summary_df\n",
        "\n",
        "\n",
        "# ----------------- RUN STEADY-STATE REPLICATION EXPERIMENT -----------------\n",
        "\n",
        "lambdas_ss = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5]\n",
        "\n",
        "per_rep_df, steady_summary_df = run_policy_grid_with_replications(\n",
        "    lambdas=lambdas_ss,\n",
        "    num_jobs_total=12000,  # total jobs per replication\n",
        "    warmup_jobs=2000,      # discard first 2000 as warm-up\n",
        "    prompt_len=100,\n",
        "    output_len=16,\n",
        "    max_batch_size=8,\n",
        "    n_rep=10,\n",
        "    seed=999,\n",
        ")\n",
        "\n",
        "print(\"=== Steady-state summary across replications ===\")\n",
        "print(steady_summary_df.round(4).to_string(index=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "cmuJXbNoYnYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_steady_state_tradeoffs(summary_df: pd.DataFrame) -> None:\n",
        "    \"\"\"\n",
        "    Plot steady-state tradeoffs from steady_summary_df:\n",
        "      1) Mean TTFT vs lambda (with 95% CI)\n",
        "      2) Mean total latency vs lambda (with 95% CI)\n",
        "      3) Throughput vs lambda (with 95% CI)\n",
        "    \"\"\"\n",
        "    if summary_df.empty:\n",
        "        print(\"No data in summary_df.\")\n",
        "        return\n",
        "\n",
        "    policies = sorted(summary_df[\"policy\"].unique())\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
        "\n",
        "    metric_specs = [\n",
        "        (\"mean_TTFT\",      \"Mean TTFT (s)\"),\n",
        "        (\"mean_Latency\",   \"Mean Total Latency (s)\"),\n",
        "        (\"Throughput\",     \"Throughput (req/s)\"),\n",
        "    ]\n",
        "\n",
        "    for ax, (col, ylabel) in zip(axes, metric_specs):\n",
        "        for pol in policies:\n",
        "            sub = summary_df[summary_df[\"policy\"] == pol].sort_values(\"lambda\")\n",
        "\n",
        "            x = sub[\"lambda\"].values\n",
        "            y = sub[col].values\n",
        "\n",
        "            # Symmetric error from CI columns (high - mean)\n",
        "            ci_high = sub[col + \"_CI_high\"].values\n",
        "            yerr = ci_high - y\n",
        "\n",
        "            ax.errorbar(\n",
        "                x,\n",
        "                y,\n",
        "                yerr=yerr,\n",
        "                marker=\"o\",\n",
        "                capsize=3,\n",
        "                linestyle=\"-\",\n",
        "                label=pol,\n",
        "            )\n",
        "\n",
        "        ax.set_xlabel(r\"Arrival rate $\\lambda$ (req/s)\")\n",
        "        ax.set_ylabel(ylabel)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    axes[0].set_title(\"Mean TTFT vs arrival rate\")\n",
        "    axes[1].set_title(\"Mean total latency vs arrival rate\")\n",
        "    axes[2].set_title(\"Throughput vs arrival rate\")\n",
        "\n",
        "    axes[0].legend(title=\"Policy\", loc=\"best\")\n",
        "\n",
        "    # On throughput plot, optionally overlay offered load (lambda)\n",
        "    lambdas_unique = np.sort(summary_df[\"lambda\"].unique())\n",
        "    axes[2].plot(\n",
        "        lambdas_unique,\n",
        "        lambdas_unique,\n",
        "        linestyle=\":\",\n",
        "        label=\"Offered load (λ)\",\n",
        "    )\n",
        "    axes[2].legend(loc=\"best\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_steady_state_tradeoffs(steady_summary_df)"
      ],
      "metadata": {
        "id": "C_ZDwWudHA-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_tail_latency(summary_df: pd.DataFrame) -> None:\n",
        "    \"\"\"\n",
        "    Plot P95 total latency vs lambda (with 95% CI) for each policy.\n",
        "    \"\"\"\n",
        "    if summary_df.empty:\n",
        "        print(\"No data in summary_df.\")\n",
        "        return\n",
        "\n",
        "    policies = sorted(summary_df[\"policy\"].unique())\n",
        "    plt.figure(figsize=(6, 4))\n",
        "\n",
        "    for pol in policies:\n",
        "        sub = summary_df[summary_df[\"policy\"] == pol].sort_values(\"lambda\")\n",
        "\n",
        "        x = sub[\"lambda\"].values\n",
        "        y = sub[\"p95_Latency\"].values\n",
        "        ci_high = sub[\"p95_Latency_CI_high\"].values\n",
        "        yerr = ci_high - y\n",
        "\n",
        "        plt.errorbar(\n",
        "            x,\n",
        "            y,\n",
        "            yerr=yerr,\n",
        "            marker=\"o\",\n",
        "            capsize=3,\n",
        "            linestyle=\"-\",\n",
        "            label=pol,\n",
        "        )\n",
        "\n",
        "    plt.xlabel(r\"Arrival rate $\\lambda$ (req/s)\")\n",
        "    plt.ylabel(\"P95 total latency (s)\")\n",
        "    plt.title(\"Tail latency (P95) vs arrival rate\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend(title=\"Policy\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plot_tail_latency(steady_summary_df)"
      ],
      "metadata": {
        "id": "ziWGil-pHYON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_selected_stats(summary_df: pd.DataFrame,\n",
        "                         lambda_values: list[float] = None) -> None:\n",
        "    \"\"\"\n",
        "    Print a compact table of key metrics for selected lambdas,\n",
        "    for each policy.\n",
        "\n",
        "    Default: all distinct lambdas in the DataFrame.\n",
        "    \"\"\"\n",
        "    if summary_df.empty:\n",
        "        print(\"No data in summary_df.\")\n",
        "        return\n",
        "\n",
        "    if lambda_values is None:\n",
        "        lambda_values = sorted(summary_df[\"lambda\"].unique())\n",
        "\n",
        "    cols_to_show = [\n",
        "        \"mean_TTFT\",\n",
        "        \"p95_TTFT\",\n",
        "        \"mean_Latency\",\n",
        "        \"p95_Latency\",\n",
        "        \"Throughput\",\n",
        "    ]\n",
        "\n",
        "    for lam in lambda_values:\n",
        "        sub = summary_df[np.isclose(summary_df[\"lambda\"], lam)]\n",
        "        if sub.empty:\n",
        "            continue\n",
        "        print(f\"\\n=== λ = {lam:.2f} ===\")\n",
        "        display_cols = [\"policy\"] + cols_to_show\n",
        "        print(sub[display_cols].round(4).to_string(index=False))\n",
        "print_selected_stats(steady_summary_df)"
      ],
      "metadata": {
        "id": "ji-wXouFHgqt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}